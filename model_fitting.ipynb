{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open data. All ECG have a lengh of 186. All the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188. Last column has the classification of the ecg : data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.load_images_ecg()\n",
    "mitbih = data['mitbih_train']\n",
    "ptbdb = data['ptbdb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we checked in data_analysis, we have unbalenced data.\n",
    "We will try first to train a model with the dataset as it is, check if there's a problem with unbalanced data, and try different approaches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#Prepare samples to train of mitbih\n",
    "mitbid_ecg = mitbih.iloc[:,:186]\n",
    "mitbid_classification = mitbih.iloc[:,-1]\n",
    "x_train = mitbid_ecg\n",
    "y_train = to_categorical(mitbid_classification)\n",
    "x_test = data['mitbih_test'].iloc[:,:186]\n",
    "y_test = to_categorical(data['mitbih_test'].iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\anaconda3\\envs\\env_datascience\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\anaconda3\\envs\\env_datascience\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\anaconda3\\envs\\env_datascience\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\anaconda3\\envs\\env_datascience\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "685/685 [==============================] - 5s 4ms/step - loss: 0.2720 - accuracy: 0.9250 - val_loss: 0.1789 - val_accuracy: 0.9524\n",
      "Epoch 2/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.1449 - accuracy: 0.9599 - val_loss: 0.1516 - val_accuracy: 0.9571\n",
      "Epoch 3/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.1178 - accuracy: 0.9668 - val_loss: 0.1277 - val_accuracy: 0.9641\n",
      "Epoch 4/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.1029 - accuracy: 0.9710 - val_loss: 0.1302 - val_accuracy: 0.9606\n",
      "Epoch 5/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9730 - val_loss: 0.1264 - val_accuracy: 0.9649\n",
      "Epoch 6/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0911 - accuracy: 0.9739 - val_loss: 0.1058 - val_accuracy: 0.9715\n",
      "Epoch 7/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0827 - accuracy: 0.9760 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
      "Epoch 8/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0779 - accuracy: 0.9776 - val_loss: 0.0971 - val_accuracy: 0.9730\n",
      "Epoch 9/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0732 - accuracy: 0.9786 - val_loss: 0.0883 - val_accuracy: 0.9754\n",
      "Epoch 10/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.0900 - val_accuracy: 0.9761\n",
      "Epoch 11/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0673 - accuracy: 0.9802 - val_loss: 0.1028 - val_accuracy: 0.9715\n",
      "Epoch 12/80\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0682 - accuracy: 0.9797 - val_loss: 0.0917 - val_accuracy: 0.9747\n",
      "Epoch 13/80\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.0869 - val_accuracy: 0.9769\n",
      "Epoch 14/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.0936 - val_accuracy: 0.9753\n",
      "Epoch 15/80\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0555 - accuracy: 0.9828 - val_loss: 0.0862 - val_accuracy: 0.9779\n",
      "Epoch 16/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.0873 - val_accuracy: 0.9781\n",
      "Epoch 17/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0879 - val_accuracy: 0.9779\n",
      "Epoch 18/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0841 - val_accuracy: 0.9785\n",
      "Epoch 19/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.0916 - val_accuracy: 0.9778\n",
      "Epoch 20/80\n",
      "685/685 [==============================] - 4s 7ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.0892 - val_accuracy: 0.9784\n",
      "Epoch 21/80\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.0837 - val_accuracy: 0.9792\n",
      "Epoch 22/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.0871 - val_accuracy: 0.9794\n",
      "Epoch 23/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0825 - val_accuracy: 0.9793\n",
      "Epoch 24/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.0842 - val_accuracy: 0.9796\n",
      "Epoch 25/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.0826 - val_accuracy: 0.9794\n",
      "Epoch 26/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.0851 - val_accuracy: 0.9802\n",
      "Epoch 27/80\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0811 - val_accuracy: 0.9814\n",
      "Epoch 28/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.0864 - val_accuracy: 0.9795\n",
      "Epoch 29/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0912 - val_accuracy: 0.9763\n",
      "Epoch 30/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0904 - val_accuracy: 0.9800\n",
      "Epoch 31/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.0839 - val_accuracy: 0.9794\n",
      "Epoch 32/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0877 - val_accuracy: 0.9804\n",
      "Epoch 33/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0907 - val_accuracy: 0.9811\n",
      "Epoch 34/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0946 - val_accuracy: 0.9795\n",
      "Epoch 35/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.0902 - val_accuracy: 0.9813\n",
      "Epoch 36/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.0901 - val_accuracy: 0.9794\n",
      "Epoch 37/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0997 - val_accuracy: 0.9795\n",
      "Epoch 38/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.1052 - val_accuracy: 0.9791\n",
      "Epoch 39/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.1002 - val_accuracy: 0.9804\n",
      "Epoch 40/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.0930 - val_accuracy: 0.9809\n",
      "Epoch 41/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
      "Epoch 42/80\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.1000 - val_accuracy: 0.9746\n",
      "Epoch 43/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0967 - val_accuracy: 0.9799\n",
      "Epoch 44/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0957 - val_accuracy: 0.9810\n",
      "Epoch 45/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.1047 - val_accuracy: 0.9801\n",
      "Epoch 46/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.1026 - val_accuracy: 0.9802\n",
      "Epoch 47/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0960 - val_accuracy: 0.9809\n",
      "Epoch 48/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.0993 - val_accuracy: 0.9814\n",
      "Epoch 49/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.1049 - val_accuracy: 0.9810\n",
      "Epoch 50/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.1155 - val_accuracy: 0.9802\n",
      "Epoch 51/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.0992 - val_accuracy: 0.9819\n",
      "Epoch 52/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.1043 - val_accuracy: 0.9813\n",
      "Epoch 53/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.1085 - val_accuracy: 0.9799\n",
      "Epoch 54/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.1152 - val_accuracy: 0.9815\n",
      "Epoch 55/80\n",
      "685/685 [==============================] - 3s 5ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.1043 - val_accuracy: 0.9817\n",
      "Epoch 56/80\n",
      "685/685 [==============================] - 5s 8ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.1077 - val_accuracy: 0.9803\n",
      "Epoch 57/80\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.1102 - val_accuracy: 0.9802\n",
      "Epoch 58/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.1125 - val_accuracy: 0.9815\n",
      "Epoch 59/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1110 - val_accuracy: 0.9804\n",
      "Epoch 60/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.1036 - val_accuracy: 0.9815\n",
      "Epoch 61/80\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.1367 - val_accuracy: 0.9777\n",
      "Epoch 62/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.1144 - val_accuracy: 0.9813\n",
      "Epoch 63/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.1104 - val_accuracy: 0.9804\n",
      "Epoch 64/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.1074 - val_accuracy: 0.9793\n",
      "Epoch 65/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.1319 - val_accuracy: 0.9803\n",
      "Epoch 66/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.1117 - val_accuracy: 0.9818\n",
      "Epoch 67/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1136 - val_accuracy: 0.9813\n",
      "Epoch 68/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.1328 - val_accuracy: 0.9790\n",
      "Epoch 69/80\n",
      "685/685 [==============================] - 6s 8ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.1266 - val_accuracy: 0.9816\n",
      "Epoch 70/80\n",
      "685/685 [==============================] - 7s 10ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.1276 - val_accuracy: 0.9815\n",
      "Epoch 71/80\n",
      "685/685 [==============================] - 4s 5ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.1313 - val_accuracy: 0.9799\n",
      "Epoch 72/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.1238 - val_accuracy: 0.9823\n",
      "Epoch 73/80\n",
      "685/685 [==============================] - 4s 6ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.1220 - val_accuracy: 0.9823\n",
      "Epoch 74/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.1235 - val_accuracy: 0.9806\n",
      "Epoch 75/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.1207 - val_accuracy: 0.9815\n",
      "Epoch 76/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.1215 - val_accuracy: 0.9814\n",
      "Epoch 77/80\n",
      "685/685 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.1198 - val_accuracy: 0.9815\n",
      "Epoch 78/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.1347 - val_accuracy: 0.9800\n",
      "Epoch 79/80\n",
      "685/685 [==============================] - 3s 4ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.1242 - val_accuracy: 0.9822\n",
      "Epoch 80/80\n",
      "685/685 [==============================] - 2s 3ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1260 - val_accuracy: 0.9813\n",
      "evaluation: \n",
      "685/685 [==============================] - 2s 2ms/step - loss: 0.1260 - accuracy: 0.9813\n"
     ]
    }
   ],
   "source": [
    "# Let's try to create a simple 2 dense layers model with a final classification with softmax (model_dense_layers_v1)\n",
    "import models\n",
    "model = models.model_dense_layers_v1()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "his = model.fit(x_train, y_train, batch_size=128, validation_data=(x_test, y_test) , epochs=80, verbose=True)\n",
    "print('evaluation: ' )\n",
    "loss , acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 2s 2ms/step\n",
      "Classe:0 | Total samples:18118 | Correct predictions: 17986 | 0.99271442764102\n",
      "Classe:1 | Total samples:556 | Correct predictions: 426 | 0.7661870503597122\n",
      "Classe:2 | Total samples:1448 | Correct predictions: 1373 | 0.9482044198895028\n",
      "Classe:3 | Total samples:162 | Correct predictions: 124 | 0.7654320987654321\n",
      "Classe:4 | Total samples:1608 | Correct predictions: 1574 | 0.9788557213930348\n"
     ]
    }
   ],
   "source": [
    "import evaluation_functions\n",
    "\n",
    "# Get predictions \n",
    "predictions = model.predict(x_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "ground_truth = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Understand number of classes the model learned more.\n",
    "evaluation_functions.print_categorical_acc(ground_truth=ground_truth, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS we see, the Classe 1 and classe 3 that have lower representation, have a accuracy of 76%\n",
    "Let's try to oversample the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ada = ADASYN(sampling_strategy='all')\n",
    "\n",
    "x_train_resample, y_train_resample = ada.fit_resample(x_train, np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.3912 - accuracy: 0.8579 - val_loss: 0.3027 - val_accuracy: 0.8912\n",
      "Epoch 2/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.1332 - accuracy: 0.9570 - val_loss: 0.2313 - val_accuracy: 0.9260\n",
      "Epoch 3/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0877 - accuracy: 0.9723 - val_loss: 0.2857 - val_accuracy: 0.9101\n",
      "Epoch 4/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0690 - accuracy: 0.9787 - val_loss: 0.2359 - val_accuracy: 0.9335\n",
      "Epoch 5/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0566 - accuracy: 0.9827 - val_loss: 0.1804 - val_accuracy: 0.9560\n",
      "Epoch 6/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.2304 - val_accuracy: 0.9392\n",
      "Epoch 7/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0419 - accuracy: 0.9872 - val_loss: 0.2126 - val_accuracy: 0.9491\n",
      "Epoch 8/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.1932 - val_accuracy: 0.9610\n",
      "Epoch 9/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.1895 - val_accuracy: 0.9659\n",
      "Epoch 10/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.1880 - val_accuracy: 0.9667\n",
      "Epoch 11/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.2071 - val_accuracy: 0.9604\n",
      "Epoch 12/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.1770 - val_accuracy: 0.9720\n",
      "Epoch 13/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.1778 - val_accuracy: 0.9747\n",
      "Epoch 14/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.1961 - val_accuracy: 0.9702\n",
      "Epoch 15/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.2553 - val_accuracy: 0.9558\n",
      "Epoch 16/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.1920 - val_accuracy: 0.9728\n",
      "Epoch 17/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.2325 - val_accuracy: 0.9614\n",
      "Epoch 18/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.2048 - val_accuracy: 0.9704\n",
      "Epoch 19/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.2071 - val_accuracy: 0.9725\n",
      "Epoch 20/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.2008 - val_accuracy: 0.9749\n",
      "Epoch 21/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.2170 - val_accuracy: 0.9713\n",
      "Epoch 22/80\n",
      "2831/2831 [==============================] - 13s 4ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.2271 - val_accuracy: 0.9665\n",
      "Epoch 23/80\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.2061 - val_accuracy: 0.9772\n",
      "Epoch 24/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.2670 - val_accuracy: 0.9579\n",
      "Epoch 25/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.2202 - val_accuracy: 0.9778\n",
      "Epoch 26/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.2262 - val_accuracy: 0.9772\n",
      "Epoch 27/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.2383 - val_accuracy: 0.9694\n",
      "Epoch 28/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.2283 - val_accuracy: 0.9767\n",
      "Epoch 29/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.2425 - val_accuracy: 0.9720\n",
      "Epoch 30/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.2379 - val_accuracy: 0.9775\n",
      "Epoch 31/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.2523 - val_accuracy: 0.9744\n",
      "Epoch 32/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.2791 - val_accuracy: 0.9650\n",
      "Epoch 33/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.2383 - val_accuracy: 0.9755\n",
      "Epoch 34/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.2460 - val_accuracy: 0.9735\n",
      "Epoch 35/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.2784 - val_accuracy: 0.9703\n",
      "Epoch 36/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.2480 - val_accuracy: 0.9770\n",
      "Epoch 37/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.2431 - val_accuracy: 0.9767\n",
      "Epoch 38/80\n",
      "2831/2831 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.2586 - val_accuracy: 0.9778\n",
      "Epoch 39/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.2824 - val_accuracy: 0.9726\n",
      "Epoch 40/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.2555 - val_accuracy: 0.9748\n",
      "Epoch 41/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.2642 - val_accuracy: 0.9772\n",
      "Epoch 42/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.2597 - val_accuracy: 0.9758\n",
      "Epoch 43/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.2592 - val_accuracy: 0.9791\n",
      "Epoch 44/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.2786 - val_accuracy: 0.9756\n",
      "Epoch 45/80\n",
      "2831/2831 [==============================] - 16s 5ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.2666 - val_accuracy: 0.9783\n",
      "Epoch 46/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.2875 - val_accuracy: 0.9754\n",
      "Epoch 47/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.2893 - val_accuracy: 0.9731\n",
      "Epoch 48/80\n",
      "2831/2831 [==============================] - 16s 5ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.2782 - val_accuracy: 0.9784\n",
      "Epoch 49/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.2661 - val_accuracy: 0.9792\n",
      "Epoch 50/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.2741 - val_accuracy: 0.9776\n",
      "Epoch 51/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.2752 - val_accuracy: 0.9773\n",
      "Epoch 52/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.2806 - val_accuracy: 0.9765\n",
      "Epoch 53/80\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2808 - val_accuracy: 0.9760\n",
      "Epoch 54/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.2951 - val_accuracy: 0.9762\n",
      "Epoch 55/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2889 - val_accuracy: 0.9795\n",
      "Epoch 56/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.2925 - val_accuracy: 0.9778\n",
      "Epoch 57/80\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2971 - val_accuracy: 0.9788\n",
      "Epoch 58/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.3275 - val_accuracy: 0.9705\n",
      "Epoch 59/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.3152 - val_accuracy: 0.9783\n",
      "Epoch 60/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.3018 - val_accuracy: 0.9759\n",
      "Epoch 61/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2928 - val_accuracy: 0.9779\n",
      "Epoch 62/80\n",
      "2831/2831 [==============================] - 10s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2972 - val_accuracy: 0.9792\n",
      "Epoch 63/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.3286 - val_accuracy: 0.9689\n",
      "Epoch 64/80\n",
      "2831/2831 [==============================] - 16s 6ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.3155 - val_accuracy: 0.9782\n",
      "Epoch 65/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.3108 - val_accuracy: 0.9746\n",
      "Epoch 66/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.3227 - val_accuracy: 0.9743\n",
      "Epoch 67/80\n",
      "2831/2831 [==============================] - 15s 5ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.3402 - val_accuracy: 0.9713\n",
      "Epoch 68/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.3087 - val_accuracy: 0.9775\n",
      "Epoch 69/80\n",
      "2831/2831 [==============================] - 12s 4ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3310 - val_accuracy: 0.9745\n",
      "Epoch 70/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.3319 - val_accuracy: 0.9753\n",
      "Epoch 71/80\n",
      "2831/2831 [==============================] - 19s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3249 - val_accuracy: 0.9767\n",
      "Epoch 72/80\n",
      "2831/2831 [==============================] - 17s 6ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.3182 - val_accuracy: 0.9771\n",
      "Epoch 73/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.3285 - val_accuracy: 0.9752\n",
      "Epoch 74/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.3347 - val_accuracy: 0.9736\n",
      "Epoch 75/80\n",
      "2831/2831 [==============================] - 13s 5ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3346 - val_accuracy: 0.9774\n",
      "Epoch 76/80\n",
      "2831/2831 [==============================] - 14s 5ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.3304 - val_accuracy: 0.9749\n",
      "Epoch 77/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.3372 - val_accuracy: 0.9738\n",
      "Epoch 78/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.3185 - val_accuracy: 0.9765\n",
      "Epoch 79/80\n",
      "2831/2831 [==============================] - 10s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.3272 - val_accuracy: 0.9772\n",
      "Epoch 80/80\n",
      "2831/2831 [==============================] - 11s 4ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.3368 - val_accuracy: 0.9744\n",
      "evaluation: \n",
      "685/685 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.9744\n",
      "685/685 [==============================] - 1s 2ms/step\n",
      "Classe:0 | Total samples:18118 | Correct predictions: 17808 | 0.9828899437023955\n",
      "Classe:1 | Total samples:556 | Correct predictions: 448 | 0.8057553956834532\n",
      "Classe:2 | Total samples:1448 | Correct predictions: 1365 | 0.9426795580110497\n",
      "Classe:3 | Total samples:162 | Correct predictions: 130 | 0.8024691358024691\n",
      "Classe:4 | Total samples:1608 | Correct predictions: 1580 | 0.9825870646766169\n"
     ]
    }
   ],
   "source": [
    "# Let's try again the same exacct model, with a more balanced data\n",
    "y_train_resample = to_categorical(y_train_resample)\n",
    "model = models.model_dense_layers_v1()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "his = model.fit(x_train_resample, y_train_resample, batch_size=128, validation_data=(x_test, y_test) , epochs=80, verbose=True)\n",
    "print('evaluation: ' )\n",
    "loss , acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Get predictions \n",
    "predictions = model.predict(x_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "ground_truth = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Understand number of classes the model learned more.\n",
    "evaluation_functions.print_categorical_acc(ground_truth=ground_truth, predictions=predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
